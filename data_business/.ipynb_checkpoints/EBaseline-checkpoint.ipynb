{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "from sklearn.cluster import KMeans\n",
    "import collections, numpy\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import librosa\n",
    "import math\n",
    "import re\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureData:\n",
    "\n",
    "    'Music audio features for genre classification'\n",
    "    hop_length = None\n",
    "\n",
    "    dir_trainfolder = \"../data/000\"\n",
    "    dir_devfolder = \"../data/001\"\n",
    "    dir_testfolder = \"../data/002\"\n",
    "    dir_all_files = \"../data\"\n",
    "\n",
    "    train_X_preprocessed_data = 'data_train_input.npy'\n",
    "    train_Y_preprocessed_data = 'data_train_target.npy'\n",
    "    dev_X_preprocessed_data = 'data_validation_input.npy'\n",
    "    dev_Y_preprocessed_data = 'data_validation_target.npy'\n",
    "    test_X_preprocessed_data = 'data_test_input.npy'\n",
    "    test_Y_preprocessed_data = 'data_test_target.npy'\n",
    "\n",
    "    train_X = train_Y = None\n",
    "    dev_X = dev_Y = None\n",
    "    test_X = test_Y = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.hop_length = 512\n",
    "        self.timeseries_length_list = []\n",
    "\n",
    "    def load_preprocess_data(self): \n",
    "        self.trainfiles_list = self.path_to_audiofiles(self.dir_trainfolder)\n",
    "        self.devfiles_list = self.path_to_audiofiles(self.dir_devfolder)\n",
    "        self.testfiles_list = self.path_to_audiofiles(self.dir_testfolder)\n",
    "\n",
    "        all_files_list = []\n",
    "        all_files_list.extend(self.trainfiles_list)\n",
    "        all_files_list.extend(self.devfiles_list)\n",
    "        all_files_list.extend(self.testfiles_list)\n",
    "\n",
    "        #self.precompute_min_timeseries_len(all_files_list)\n",
    "        print(\"[DEBUG] total number of files: \" + str(len(self.timeseries_length_list)))\n",
    "\n",
    "        # Training set\n",
    "        self.train_X, self.train_Y = self.extract_audio_features(self.trainfiles_list)\n",
    "        with open(self.train_X_preprocessed_data, 'wb') as f:\n",
    "            np.save(f, self.train_X)\n",
    "        with open(self.train_Y_preprocessed_data, 'wb') as f:\n",
    "            self.train_Y = self.one_hot(self.train_Y)\n",
    "            np.save(f, self.train_Y)\n",
    "\n",
    "        # Validation set\n",
    "        self.dev_X, self.dev_Y = self.extract_audio_features(self.devfiles_list)\n",
    "        with open(self.dev_X_preprocessed_data, 'wb') as f:\n",
    "            np.save(f, self.dev_X)\n",
    "        with open(self.dev_Y_preprocessed_data, 'wb') as f:\n",
    "            self.dev_Y = self.one_hot(self.dev_Y)\n",
    "            np.save(f, self.dev_Y)\n",
    "\n",
    "        # Test set\n",
    "        self.test_X, self.test_Y = self.extract_audio_features(self.testfiles_list)\n",
    "        with open(self.test_X_preprocessed_data, 'wb') as f:\n",
    "            np.save(f, self.test_X)\n",
    "        with open(self.test_Y_preprocessed_data, 'wb') as f:\n",
    "            self.test_Y = self.one_hot(self.test_Y)\n",
    "            np.save(f, self.test_Y)\n",
    "\n",
    "    def load_deserialize_data(self):\n",
    "\n",
    "        self.train_X = np.load(self.train_X_preprocessed_data)\n",
    "        self.train_Y = np.load(self.train_Y_preprocessed_data)\n",
    "\n",
    "        self.dev_X = np.load(self.dev_X_preprocessed_data)\n",
    "        self.dev_Y = np.load(self.dev_Y_preprocessed_data)\n",
    "\n",
    "        self.test_X = np.load(self.test_X_preprocessed_data)\n",
    "        self.test_Y = np.load(self.test_Y_preprocessed_data)\n",
    "\n",
    "    def precompute_min_timeseries_len(self, list_of_audiofiles):\n",
    "        for file in list_of_audiofiles:\n",
    "            print(\"Loading \" + str(file))\n",
    "            y, sr = librosa.load(file)\n",
    "            self.timeseries_length_list.append(math.ceil(len(y) / self.hop_length))\n",
    "\n",
    "    def extract_audio_features(self, list_of_audiofiles):\n",
    "        #timeseries_length = min(self.timeseries_length_list)\n",
    "        timeseries_length = 128 # was 128 previously\n",
    "        t_length = 12\n",
    "        data = np.zeros((len(list_of_audiofiles), timeseries_length, 33), dtype=np.float64)\n",
    "        target = []\n",
    "\n",
    "        for i, file in enumerate(list_of_audiofiles):\n",
    "            y, sr = librosa.load(file)\n",
    "            \n",
    "            mfcc = []\n",
    "            spectral_center = []\n",
    "            chroma = []\n",
    "            spectral_contrast = []\n",
    "            \n",
    "        \n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=self.hop_length, n_mfcc=13)\n",
    "#             spectral_center = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=self.hop_length)\n",
    "#             chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
    "#             spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=self.hop_length)\n",
    "            \n",
    "            \n",
    "\n",
    "            splits = re.split('[ .]', file)\n",
    "            genre = re.split('[ /]', splits[1])[3]\n",
    "            target.append(genre)\n",
    "\n",
    "\n",
    "            \n",
    "            data[i, :, 0:13] = mfcc.T[0:timeseries_length, :]\n",
    "#             data[i, :, 13:14] = spectral_center.T[0:timeseries_length, :]\n",
    "#             data[i, :, 14:26] = chroma.T[0:timeseries_length, :]\n",
    "#             data[i, :, 26:33] = spectral_contrast.T[0:timeseries_length, :]\n",
    "\n",
    "            print(\"Extracted features audio track %i of %i.\" % (i + 1, len(list_of_audiofiles)))\n",
    "\n",
    "        return data, np.expand_dims(np.asarray(target), axis=1)\n",
    "\n",
    "    def one_hot(self, Y_genre_strings):\n",
    "        y_one_hot = np.zeros((Y_genre_strings.shape[0], len(self.genre_list)))\n",
    "        for i, genre_string in enumerate(Y_genre_strings):\n",
    "            index = self.genre_list.index(genre_string)\n",
    "            y_one_hot[i, index] = 1\n",
    "        return y_one_hot\n",
    "\n",
    "    def path_to_audiofiles(self, dir_folder):\n",
    "        list_of_audio = []\n",
    "        for file in os.listdir(dir_folder):\n",
    "            if file.endswith(\".au\"):\n",
    "                directory = \"%s/%s\" % (dir_folder, file)\n",
    "                list_of_audio.append(directory)\n",
    "        return list_of_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_features = FeatureData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '../data/000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2c1e95431c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msong_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-daf2ad5d37c1>\u001b[0m in \u001b[0;36mload_preprocess_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainfiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_audiofiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_trainfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevfiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_audiofiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_devfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestfiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_audiofiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_testfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-daf2ad5d37c1>\u001b[0m in \u001b[0;36mpath_to_audiofiles\u001b[0;34m(self, dir_folder)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpath_to_audiofiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mlist_of_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".au\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdir_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '../data/000'"
     ]
    }
   ],
   "source": [
    "song_features.load_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
