{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "from sklearn.cluster import KMeans\n",
    "import collections, numpy\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import librosa\n",
    "import math\n",
    "import re\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhmani/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/anirudhmani/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/anirudhmani/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,11,13,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load metadata and features.\n",
    "tracks = pd.read_csv('fma_metadata/tracks.csv')\n",
    "r_tracks = pd.read_csv('fma_metadata/raw_tracks.csv')\n",
    "genres = pd.read_csv('fma_metadata/genres.csv')\n",
    "features = pd.read_csv('fma_metadata/features.csv')\n",
    "echonest = pd.read_csv('fma_metadata/echonest.csv')\n",
    "r_artists = pd.read_csv('fma_metadata/raw_artists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall subset\n",
    "tracks_sm = tracks.loc[(tracks['set.1'] == 'small') & (tracks['set'] == 'training')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset based on artists in set\n",
    "# load\n",
    "def load_spot_rel_artists(name):\n",
    "    with open(name, 'rb') as handle:\n",
    "        thing = pickle.load(handle)   \n",
    "    return thing\n",
    "artist_rel = load_spot_rel_artists(\"saved_data/artist_rel_small_training.pickle\")\n",
    "\n",
    "\n",
    "# ipd.display(features.columns[253:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artist_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting Business, Creating Master tables\n",
    "\n",
    "# Creating Condensed Artist Map, and Master 2D Table\n",
    "artist_all = {}\n",
    "\n",
    "for key in artist_rel:\n",
    "    artist_all[key] = set()\n",
    "\n",
    "for key in artist_rel:\n",
    "    for elem in artist_rel[key]:\n",
    "        if artist_rel.get(elem, None) is not None:\n",
    "            artist_all[key].add(elem)\n",
    "            artist_all[elem].add(key)\n",
    "\n",
    "# assert len(artist_all) == len(artist_rel)  \n",
    "# deleting artists with no related artist in set\n",
    "keys = artist_all.keys()\n",
    "for key in keys:\n",
    "    if not artist_all[key]:\n",
    "        del artist_all[key]\n",
    "#         pass\n",
    "    else:\n",
    "        artist_all[key] = list(artist_all[key])\n",
    "        \n",
    "# Artist Index Map\n",
    "artist_index = {}\n",
    "for i, a in enumerate(artist_all.keys()):\n",
    "    artist_index[a] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_tracks = tracks_sm.loc[(tracks_sm['artist.12'] == artist_all.keys()[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19350    30690\n",
       "22365    34996\n",
       "25121    38847\n",
       "29414    44342\n",
       "31871    48307\n",
       "Name: Unnamed: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_tracks['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureData:\n",
    "\n",
    "    'Music audio features for genre classification'\n",
    "    hop_length = None\n",
    "\n",
    "    dir_trainfolder = \"/Users/anirudhmani/Prog/thesis_related/data/fma_small_consolidated\"\n",
    "    dir_devfolder = \"/Users/anirudhmani/Prog/thesis_related/data/fma_small/001\"\n",
    "    dir_testfolder = \"/Users/anirudhmani/Prog/thesis_related/data/fma_small/002\"\n",
    "#     dir_all_files = \"/Users/anirudhmani/Prog/thesis_related/data\"\n",
    "\n",
    "    train_X_preprocessed_data = 'data_train_input.npy'\n",
    "    train_Y_preprocessed_data = 'data_train_target.npy'\n",
    "    dev_X_preprocessed_data = 'data_validation_input.npy'\n",
    "    dev_Y_preprocessed_data = 'data_validation_target.npy'\n",
    "    test_X_preprocessed_data = 'data_test_input.npy'\n",
    "    test_Y_preprocessed_data = 'data_test_target.npy'\n",
    "\n",
    "    train_X = train_Y = None\n",
    "    dev_X = dev_Y = None\n",
    "    test_X = test_Y = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.hop_length = 512\n",
    "        self.timeseries_length_list = []\n",
    "\n",
    "    def load_preprocess_data(self): \n",
    "        self.trainfiles_list = self.path_to_audiofiles(self.dir_trainfolder)\n",
    "        self.devfiles_list = self.path_to_audiofiles(self.dir_devfolder)\n",
    "        self.testfiles_list = self.path_to_audiofiles(self.dir_testfolder)\n",
    "\n",
    "        all_files_list = []\n",
    "        all_files_list.extend(self.trainfiles_list)\n",
    "        all_files_list.extend(self.devfiles_list)\n",
    "        all_files_list.extend(self.testfiles_list)\n",
    "\n",
    "        #self.precompute_min_timeseries_len(all_files_list)\n",
    "        print(\"[DEBUG] total number of files: \" + str(len(self.timeseries_length_list)))\n",
    "\n",
    "        # Training set\n",
    "        self.train_X = self.extract_audio_features(self.trainfiles_list)\n",
    "        with open(self.train_X_preprocessed_data, 'wb') as f:\n",
    "            np.save(f, self.train_X)\n",
    "#         with open(self.train_Y_preprocessed_data, 'wb') as f:\n",
    "#             self.train_Y = self.one_hot(self.train_Y)\n",
    "#             np.save(f, self.train_Y)\n",
    "\n",
    "        # Validation set\n",
    "#         self.dev_X, self.dev_Y = self.extract_audio_features(self.devfiles_list)\n",
    "#         with open(self.dev_X_preprocessed_data, 'wb') as f:\n",
    "#             np.save(f, self.dev_X)\n",
    "#         with open(self.dev_Y_preprocessed_data, 'wb') as f:\n",
    "#             self.dev_Y = self.one_hot(self.dev_Y)\n",
    "#             np.save(f, self.dev_Y)\n",
    "\n",
    "        # Test set\n",
    "#         self.test_X, self.test_Y = self.extract_audio_features(self.testfiles_list)\n",
    "#         with open(self.test_X_preprocessed_data, 'wb') as f:\n",
    "#             np.save(f, self.test_X)\n",
    "#         with open(self.test_Y_preprocessed_data, 'wb') as f:\n",
    "#             self.test_Y = self.one_hot(self.test_Y)\n",
    "#             np.save(f, self.test_Y)\n",
    "\n",
    "    def load_deserialize_data(self):\n",
    "\n",
    "        self.train_X = np.load(self.train_X_preprocessed_data)\n",
    "#         self.train_Y = np.load(self.train_Y_preprocessed_data)\n",
    "\n",
    "        self.dev_X = np.load(self.dev_X_preprocessed_data)\n",
    "#         self.dev_Y = np.load(self.dev_Y_preprocessed_data)\n",
    "\n",
    "        self.test_X = np.load(self.test_X_preprocessed_data)\n",
    "#         self.test_Y = np.load(self.test_Y_preprocessed_data)\n",
    "\n",
    "    def precompute_min_timeseries_len(self, list_of_audiofiles):\n",
    "        for file in list_of_audiofiles:\n",
    "            print(\"Loading \" + str(file))\n",
    "            y, sr = librosa.load(file)\n",
    "            self.timeseries_length_list.append(math.ceil(len(y) / self.hop_length))\n",
    "\n",
    "    def extract_audio_features(self, list_of_audiofiles):\n",
    "        #timeseries_length = min(self.timeseries_length_list)\n",
    "        timeseries_length = 128 # was 128 previously\n",
    "        t_length = 12\n",
    "        data = np.zeros((len(list_of_audiofiles), timeseries_length, 13), dtype=np.float64)\n",
    "        target = []\n",
    "\n",
    "        for i, file in enumerate(list_of_audiofiles):\n",
    "            try:\n",
    "                y, sr = librosa.load(file)\n",
    "                       \n",
    "                mfcc = []\n",
    "                spectral_center = []\n",
    "                chroma = []\n",
    "                spectral_contrast = []\n",
    "\n",
    "        \n",
    "                mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=self.hop_length, n_mfcc=13)\n",
    "#             spectral_center = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=self.hop_length)\n",
    "#             chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
    "#             spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=self.hop_length)\n",
    "            \n",
    "            \n",
    "\n",
    "                splits = re.split('[ .]', file)\n",
    "#             genre = re.split('[ /]', splits[1])[3]\n",
    "#             target.append(genre)\n",
    "\n",
    "\n",
    "            \n",
    "                data[i, :, 0:13] = mfcc.T[0:timeseries_length, :]\n",
    "#             data[i, :, 13:14] = spectral_center.T[0:timeseries_length, :]\n",
    "#             data[i, :, 14:26] = chroma.T[0:timeseries_length, :]\n",
    "#             data[i, :, 26:33] = spectral_contrast.T[0:timeseries_length, :]\n",
    "\n",
    "#             print(\"Extracted features audio track %i of %i.\" % (i + 1, len(list_of_audiofiles)))\n",
    "\n",
    "            except:\n",
    "                print \"error reading.....continuing\"\n",
    "                continue\n",
    "\n",
    "        print(\"Extracted audio features .....\")\n",
    "        return data\n",
    "\n",
    "    def one_hot(self, Y_genre_strings):\n",
    "        y_one_hot = np.zeros((Y_genre_strings.shape[0], len(self.genre_list)))\n",
    "        for i, genre_string in enumerate(Y_genre_strings):\n",
    "            index = self.genre_list.index(genre_string)\n",
    "            y_one_hot[i, index] = 1\n",
    "        return y_one_hot\n",
    "\n",
    "    def path_to_audiofiles(self, dir_folder):\n",
    "        list_of_audio = []\n",
    "        for file in os.listdir(dir_folder):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                directory = \"%s/%s\" % (dir_folder, file)\n",
    "                list_of_audio.append(directory)\n",
    "        return list_of_audio\n",
    "    \n",
    "    def get_meaned(self, tracks_data, ax):     \n",
    "        return np.mean(tracks_data, axis=ax)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_features = FeatureData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainfiles_list = song_features.path_to_audiofiles(song_features.dir_trainfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_features.load_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudhmani/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# creating a table ntry for pull path of track\n",
    "\n",
    "# artist_tracks['track_path'] = \"%s/%s\" % (song_features.dir_trainfolder, artist_tracks['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainfiles_list[0].split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "# changing trainfiles list per artist\n",
    "artist_tracklist = {}\n",
    "for i, a in enumerate(artist_all.keys()):\n",
    "    for s in tracks_sm.loc[(tracks_sm['artist.12'] == a)]['Unnamed: 0']:\n",
    "        \n",
    "        if a in artist_tracklist:\n",
    "            artist_tracklist[a].append(\"%s/%s.mp3\" % (song_features.dir_trainfolder, s))  \n",
    "        else:\n",
    "            artist_tracklist[a] = [\"%s/%s.mp3\" % (song_features.dir_trainfolder, s)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_data = song_features.train_X # num of tracks * Time Length * Num of Features\n",
    "tracks_data = tracks_data.reshape(tracks_data.shape[0]*tracks_data.shape[1], tracks_data.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_data = song_features.get_meaned(tracks_data, 1) # get mean of features per track, num of tracks * Num of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bog_model(data, num_clusters):\n",
    "    # all features in all songs in all artists\n",
    "    # X = get_data\n",
    "#     A = 100\n",
    "#     F = 13\n",
    "#     all_features = numpy.random.rand(A, F)\n",
    "    model = KMeans(num_clusters)\n",
    "    model.fit(data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_bog_model(tracks_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7936, 13)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_spot_rel_artists(name, table):\n",
    "    with open('saved_data/%s.pickle'%name, 'wb') as writer:\n",
    "        pickle.dump(table, writer, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_spot_rel_artists('cluster_model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output is num_artists * num_clusters \n",
    "def construct_artist_similarity_matrix(model, data_folder, num_clusters, num_artists):\n",
    "    artist_similarity_matrix = numpy.zeros((num_artists, num_clusters))\n",
    "\n",
    "    # for artist_index, artist in enumerate(data):\n",
    "    for artist_index, artist in enumerate(range(num_artists)):\n",
    "        artist_feature = []\n",
    "        # for song in artist:\n",
    "        for song in range(10):\n",
    "            song_features = []\n",
    "            # for clip in song:\n",
    "            for clip in range(10):\n",
    "                # is of 1 X F dimensions\n",
    "                # features = get_feature(clip)\n",
    "                features = numpy.random.rand(1,13)\n",
    "                song_features.append(features)\n",
    "                \n",
    "            song_features = numpy.vstack(song_features)\n",
    "            artist_feature.append(get_histogram_song(song_features, model, num_clusters))\n",
    "        artist_feature = numpy.vstack(artist_feature)\n",
    "        artist_similarity_matrix[artist_index, :] = get_artist_feature(artist_feature)\n",
    "    return artist_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_similarity_matrix = construct_artist_similarity_matrix(model, data_folder, num_clusters, num_artists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
